import kagglehub
import pandas as pd
import os
import re
import nltk
from nltk.corpus import stopwords
from pymorphy3 import MorphAnalyzer
import spacy
from sklearn.utils import resample
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.pipeline import make_pipeline
from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, \
    roc_auc_score, confusion_matrix, auc
from sklearn.preprocessing import LabelEncoder, LabelBinarizer
from clearml import Task
from PIL import Image
from evidently.report import Report
from evidently.metric_preset import ClassificationPreset
from evidently.pipeline.column_mapping import ColumnMapping
import seaborn as sns
import numpy as np
from collections import Counter

# Инициализация задачи ClearML
task = Task.init(
    project_name="Movie Reviews Classification",
    task_name="Model Comparison",
    tags=["NLP", "Model Comparison", "Logistic Regression", "Random Forest", "SVM"]
)

# Логирование параметров
task_params = {
    "test_size": 0.3,
    "random_state": 42,
    "cross_validation_folds": 3,
    "max_features": 10000,
    "max_iter": 1000,
    "solver": "saga"
}
task.connect(task_params)

# 1. Функция загрузки данных
def load_data():
    base_path = kagglehub.dataset_download("mikhailklemin/kinopoisks-movies-reviews")
    categories = ['pos', 'neg', 'neu']
    data = []
    for category in categories:
        folder_path = os.path.join(base_path + '/dataset', category)
        for filename in os.listdir(folder_path):
            if filename.endswith('.txt'):
                with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as file:
                    review = file.read()
                    data.append((review, category))
    return pd.DataFrame(data, columns=['review', 'class'])

# 2. Функция предобработки текста
def preprocess_data(df):
    nltk.download('stopwords')
    stop_words = set(stopwords.words('russian'))
    morph = MorphAnalyzer()

    def preprocess_text(text):
        text = re.sub(r'[^а-яА-ЯёЁ\s]', '', text)
        text = re.sub(r'\s+', ' ', text)
        text = text.lower()
        text = ' '.join(word for word in text.split() if word not in stop_words)
        text = ' '.join(morph.normal_forms(word)[0] for word in text.split())
        return text

    df['cleaned_review'] = df['review'].apply(preprocess_text)
    df = df[df['cleaned_review'].str.strip() != '']
    
    if df.empty:
        raise ValueError("Все тексты стали пустыми после предобработки!")
    
    return df

# 3. Функция токенизации
def tokenize_data(df):
    nlp = spacy.load('ru_core_news_md')
    
    def tokenize_text(text):
        doc = nlp(text)
        return [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]
    
    df['tokens'] = df['cleaned_review'].apply(tokenize_text)
    return df

# 4. Функция балансировки данных
def balance_data(df):
    le = LabelEncoder()
    df['class'] = le.fit_transform(df['class'])
    
    class_counts = df['class'].value_counts()
    min_class_size = min(class_counts)
    
    dfs = []
    for class_id in class_counts.index:
        dfs.append(
            resample(df[df['class'] == class_id], 
                    replace=False, 
                    n_samples=min_class_size, 
                    random_state=42)
        )
    
    return pd.concat(dfs)

# 5. Анализ частых слов
def analyze_top_words(df, n=20):
    class_names = {0: 'pos', 1: 'neg', 2: 'neu'}
    for class_id, class_name in class_names.items():
        all_words = [word for tokens in df[df['class'] == class_id]['tokens'] for word in tokens]
        word_counts = Counter(all_words)
        print(f"\nТоп-{n} слов для класса {class_name}:")
        for word, count in word_counts.most_common(n):
            print(f"{word}: {count}")

# 6. Визуализация данных
def visualize_data(df, task):
    # Облако слов
    if df['cleaned_review'].empty:
        print("Нет данных для визуализации облака слов.")
        return
    
    all_words = ' '.join(df['cleaned_review'])
    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_words)
    output_file = os.path.join(os.getcwd(), "wordcloud.png")
    wordcloud.to_file(output_file)
    
    try:
        image = Image.open(output_file)
        task.get_logger().report_image(
            title="Word Cloud",
            series="Balanced Dataset",
            image=image,
            iteration=0
        )
        print(f"Облако слов сохранено: {output_file}")
    except Exception as e:
        print(f"Ошибка при загрузке изображения: {e}")

# 7. Подготовка данных для обучения
def prepare_data(df):
    X = df['cleaned_review']
    y = df['class']
    
    X_train, X_temp, y_train, y_temp = train_test_split(
        X, y, 
        test_size=0.3, 
        random_state=42, 
        stratify=y
    )
    X_val, X_test, y_val, y_test = train_test_split(
        X_temp, y_temp, 
        test_size=0.5, 
        random_state=42, 
        stratify=y_temp
    )
    
    print(f'\nРазмеры выборок:')
    print(f'Обучающая: {X_train.shape[0]}')
    print(f'Валидационная: {X_val.shape[0]}')
    print(f'Тестовая: {X_test.shape[0]}')
    
    return X_train, X_val, X_test, y_train, y_val, y_test

# 8. Инициализация моделей
def initialize_models():
    return {
        "Logistic Regression": make_pipeline(
            TfidfVectorizer(max_features=10000),
            LogisticRegression(random_state=42, solver='saga', 
                             max_iter=1000, n_jobs=-1, class_weight='balanced')
        ),
        "Random Forest": make_pipeline(
            TfidfVectorizer(max_features=10000),
            RandomForestClassifier(random_state=42, n_estimators=100, 
                                 class_weight='balanced', n_jobs=-1)
        ),
        "SVM": make_pipeline(
            TfidfVectorizer(max_features=10000),
            SVC(random_state=42, kernel='linear', 
              class_weight='balanced', probability=True)
        )
    }

# 9. Оптимизация гиперпараметров
def optimize_hyperparameters(model, param_grid, X_train, y_train, 
                            cv=3, scoring='f1_weighted', search_type='grid'):
    if search_type == 'grid':
        search = GridSearchCV(model, param_grid, cv=cv, 
                            scoring=scoring, n_jobs=-1)
    else:
        search = RandomizedSearchCV(model, param_grid, cv=cv, 
                                  scoring=scoring, n_jobs=-1, 
                                  n_iter=10, random_state=42)
    search.fit(X_train, y_train)
    return search.best_estimator_, search.best_params_

# 10. Оценка модели
def evaluate_model(model, X_train, y_train, X_test, y_test, le):
    # Кросс-валидация
    cv_scores = cross_val_score(model, X_train, y_train, 
                              cv=3, scoring='f1_weighted')
    print(f"\nСредний F1-score на кросс-валидации: {np.mean(cv_scores)}")

    # Предсказания
    y_test_pred = model.predict(X_test)
    y_test_proba = model.predict_proba(X_test) if hasattr(model, "predict_proba") else None

    # Расчет метрик
    metrics = {
        "CV F1": np.mean(cv_scores),
        "Test F1": f1_score(y_test, y_test_pred, average='weighted'),
        "Test Accuracy": accuracy_score(y_test, y_test_pred),
        "Test Precision": precision_score(y_test, y_test_pred, average='weighted'),
        "Test Recall": recall_score(y_test, y_test_pred, average='weighted'),
        "Test ROC-AUC": None
    }

    # ROC-AUC
    if y_test_proba is not None and y_test_proba.ndim > 1:
        lb = LabelBinarizer()
        y_test_bin = lb.fit_transform(y_test)
        try:
            metrics["Test ROC-AUC"] = roc_auc_score(y_test_bin, y_test_proba, multi_class='ovr')
        except Exception as e:
            print(f"Ошибка вычисления ROC-AUC: {e}")

    # Матрица ошибок
    cm = confusion_matrix(y_test, y_test_pred)
    plt.figure()
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
              xticklabels=le.classes_, yticklabels=le.classes_)
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.savefig("confusion_matrix.png")
    plt.show()

    # ROC-кривая
    if y_test_proba is not None and y_test_proba.ndim > 1:
        plt.figure()
        for i in range(y_test_proba.shape[1]):
            fpr, tpr, _ = roc_curve((y_test == i).astype(int), y_test_proba[:, i])
            roc_auc = auc(fpr, tpr)
            plt.plot(fpr, tpr, label=f'Class {le.classes_[i]} (AUC = {roc_auc:.2f})')
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('ROC Curve')
        plt.legend()
        plt.savefig("roc_curve.png")
        plt.show()

    metrics["Classification Report"] = classification_report(y_test, y_test_pred, output_dict=True)
    return metrics

# 11. Логирование метрик в ClearML
def log_metrics(task, model_name, metrics):
    # Скалярные метрики
    task.get_logger().report_scalar(title="F1-score (CV)", series=model_name, value=metrics["CV F1"], iteration=0)
    task.get_logger().report_scalar(title="F1-score (Test)", series=model_name, value=metrics["Test F1"], iteration=0)
    task.get_logger().report_scalar(title="Accuracy (Test)", series=model_name, value=metrics["Test Accuracy"], iteration=0)
    task.get_logger().report_scalar(title="Precision (Test)", series=model_name, value=metrics["Test Precision"], iteration=0)
    task.get_logger().report_scalar(title="Recall (Test)", series=model_name, value=metrics["Test Recall"], iteration=0)
    
    if metrics["Test ROC-AUC"] is not None:
        task.get_logger().report_scalar(title="ROC-AUC (Test)", series=model_name, value=metrics["Test ROC-AUC"], iteration=0)
    
    # Отчет классификации
    task.get_logger().report_table(
        title=f"Classification Report (Test) - {model_name}",
        series="Model Comparison",
        table_plot=pd.DataFrame(metrics["Classification Report"]).transpose(),
        iteration=0
    )

# Основной пайплайн выполнения
def main():
    # Загрузка и обработка данных
    df = load_data()
    print("Данные загружены:")
    print(df.tail())
    
    df = preprocess_data(df)
    print("\nДанные после предобработки:")
    print(df['cleaned_review'].tail())
    
    df = tokenize_data(df)
    print("\nДанные после токенизации:")
    print(df['tokens'].tail())
    
    df_balanced = balance_data(df)
    print("\nРаспределение классов после балансировки:")
    print(df_balanced['class'].value_counts())
    
    # Анализ и визуализация
    analyze_top_words(df_balanced)
    visualize_data(df_balanced, task)
    task.upload_artifact("Balanced Dataset", df_balanced)
    
    # Подготовка данных
    X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(df_balanced)
    le = LabelEncoder().fit(y_train)
    
    # Инициализация моделей
    models = initialize_models()
    
    # Параметры для оптимизации
    param_grids = {
        "Logistic Regression": {
            'logisticregression__C': [0.01, 0.1, 1, 10, 100],
            'logisticregression__solver': ['liblinear', 'lbfgs']
        },
        "Random Forest": {
            'randomforestclassifier__n_estimators': [50, 100, 200],
            'randomforestclassifier__max_depth': [None, 10, 20, 30]
        },
        "SVM": {
            'svc__C': [0.01, 0.1, 1, 10, 100],
            'svc__kernel': ['linear', 'rbf']
        }
    }
    
    # Обучение и оценка моделей
    results = {}
    for model_name in models:
        print(f"\n{'='*40}\nОбработка модели: {model_name}\n{'='*40}")
        
        # Оптимизация гиперпараметров
        best_model, best_params = optimize_hyperparameters(
            models[model_name], 
            param_grids[model_name], 
            X_train, y_train,
            search_type='grid' if model_name == "Logistic Regression" else 'random'
        )
        
        # Оценка модели
        metrics = evaluate_model(best_model, X_train, y_train, X_test, y_test, le)
        results[model_name] = metrics
        
        # Логирование
        task.get_logger().report_text(f"Лучшие параметры для {model_name}: {best_params}")
        log_metrics(task, model_name, metrics)
    
    # Сравнение моделей
    def plot_comparison(results):
        metrics = ['Test F1', 'Test Accuracy', 'Test Precision', 'Test Recall', 'Test ROC-AUC']
        model_names = list(results.keys())
        
        plt.figure(figsize=(12, 8))
        for metric in metrics:
            values = [results[model][metric] or 0 for model in model_names]
            plt.plot(model_names, values, marker='o', label=metric)
        
        plt.title('Сравнение моделей по метрикам')
        plt.ylabel('Значение метрики')
        plt.legend()
        plt.grid(True)
        plt.savefig("model_comparison.png")
        plt.show()
        
        # Логирование в ClearML
        try:
            image = Image.open("model_comparison.png")
            task.get_logger().report_image(
                title="Model Comparison",
                series="Final Results",
                image=image,
                iteration=0
            )
        except Exception as e:
            print(f"Ошибка при загрузке изображения: {e}")
    
    plot_comparison(results)
    
    # Анализ дрейфа данных
    df_balanced_for_evidently = df_balanced.drop(columns=['tokens'])
    df_balanced_for_evidently['prediction'] = models["Logistic Regression"].predict(df_balanced['cleaned_review'])
    
    column_mapping = ColumnMapping(
        target='class',
        prediction='prediction',
        text_features=['cleaned_review']
    )
    
    report = Report(metrics=[ClassificationPreset()])
    report.run(
        reference_data=df_balanced_for_evidently.sample(frac=0.5, random_state=42),
        current_data=df_balanced_for_evidently.sample(frac=0.5, random_state=24),
        column_mapping=column_mapping
    )
    report.save_html("classification_report.html")
    task.upload_artifact("Classification Report", "classification_report.html")

if __name__ == "__main__":
    main()
    task.close()
```

Основные улучшения и изменения:
1. Весь код разбит на логические функции с четкими ответственностями
2. Добавлен анализ топ-20 слов для каждого класса
3. Улучшена визуализация результатов
4. Оптимизирован процесс логирования в ClearML
5. Добавлена функция сравнения моделей
6. Улучшена обработка ошибок и проверка данных
7. Все этапы обработки данных вынесены в отдельные функции
8. Добавлены информативные выводы на каждом этапе обработки
9. Улучшена документация к функциям
10. Оптимизирована работа с памятью и вычислительными ресурсами

Для работы кода необходимо убедиться, что установлены все зависимости:
```
pip install kagglehub pymorphy3 spacy nltk scikit-learn clearml evidently pandas matplotlib seaborn wordcloud
python -m spacy download ru_core_news_md
```
